# =============================================================================
# Action Builder Environment Configuration
# =============================================================================
#
# ActionBuilder uses Vercel AI SDK with multi-provider support.
# Provider auto-detection priority: OpenRouter > OpenAI > Anthropic > Bedrock
#
# Set at least ONE API key (or AWS credentials for Bedrock) from the options below.
#
# =============================================================================

# -----------------------------------------------------------------------------
# Database (required for database features)
# -----------------------------------------------------------------------------
DATABASE_URL=postgres://user:password@localhost:5432/actionbook

# -----------------------------------------------------------------------------
# HTTP Proxy (optional)
# -----------------------------------------------------------------------------
# Configure proxy for LLM API requests (useful in network-restricted environments)
# Supports both HTTPS_PROXY and HTTP_PROXY environment variables
#
# IMPORTANT: When using proxy, Stagehand (browser automation) only supports:
#   - OpenRouter (recommended)
#   - OpenAI
# Anthropic SDK does NOT support HTTP proxy natively. If you need proxy with
# Anthropic models, use OpenRouter which routes to Anthropic via OpenAI-compatible API.
#
# HTTPS_PROXY=http://127.0.0.1:7890
# HTTP_PROXY=http://127.0.0.1:7890

# -----------------------------------------------------------------------------
# LLM Provider Configuration (choose ONE)
# -----------------------------------------------------------------------------
# ActionBuilder auto-detects which provider to use based on available API keys.
# Priority: OPENROUTER > OPENAI > ANTHROPIC > BEDROCK

# Option 1: OpenRouter (recommended - access to all models via single API)
OPENROUTER_API_KEY=sk-or-v1-your-api-key-here
OPENROUTER_MODEL=anthropic/claude-sonnet-4

# Option 2: OpenAI directly
# OPENAI_API_KEY=sk-your-openai-key
# OPENAI_MODEL=gpt-4o

# Option 3: Anthropic directly
# ANTHROPIC_API_KEY=sk-ant-your-key
# ANTHROPIC_MODEL=claude-sonnet-4-5

# Option 4: AWS Bedrock (uses AWS credentials)
# Uses Vercel AI SDK (@ai-sdk/amazon-bedrock) for both AIClient and Stagehand.
# Stagehand uses AISdkClient to bypass model name validation.
#
# AWS_ACCESS_KEY_ID=your-access-key-id
# AWS_SECRET_ACCESS_KEY=your-secret-access-key
# AWS_SESSION_TOKEN=your-session-token          # Optional, for temporary credentials
# AWS_REGION=us-east-1                          # Or AWS_BEDROCK_REGION
# AWS_BEDROCK_MODEL=anthropic.claude-3-5-sonnet-20241022-v2:0

# -----------------------------------------------------------------------------
# Stagehand Browser LLM Configuration (Optional)
# -----------------------------------------------------------------------------
# Stagehand (browser automation) uses a separate LLM instance for page observation.
# It auto-detects provider from the same API keys above.
#
# STAGEHAND_MODEL format depends on the provider:
#   - OpenRouter: OpenAI model names (e.g., gpt-4o, gpt-4o-mini)
#   - OpenAI: OpenAI model names (e.g., gpt-4o, gpt-4o-mini)
#   - Anthropic: Claude model names (e.g., claude-sonnet-4-20250514)
#   - Bedrock: Bedrock model IDs (e.g., anthropic.claude-3-5-sonnet-20241022-v2:0)
#
# Priority: STAGEHAND_MODEL > provider-specific model env var > default
#
STAGEHAND_MODEL=gpt-4o

# -----------------------------------------------------------------------------
# Selector Optimizer Configuration (Optional)
# -----------------------------------------------------------------------------
# SelectorOptimizer uses LLM to batch analyze and filter unstable selectors.
# Uses a smaller/faster model by default for cost efficiency.
#
# SELECTOR_OPTIMIZER_MODEL format depends on the provider (same as STAGEHAND_MODEL):
#   - OpenRouter: gpt-4o-mini (default)
#   - OpenAI: gpt-4o-mini (default)
#   - Anthropic: claude-3-5-haiku-latest (default)
#   - Bedrock: anthropic.claude-3-5-haiku-20241022-v1:0 (default)
#
# SELECTOR_OPTIMIZER_MODEL=gpt-4o-mini

# -----------------------------------------------------------------------------
# Task Queue Coordinator Configuration
# -----------------------------------------------------------------------------
# These settings control the Task Queue Coordinator behavior.
# Used by: pnpm coordinator, pnpm dev

# Coordinator Settings
# --------------------
# Maximum number of concurrent build_tasks (different sources processed simultaneously)
ACTION_BUILDER_BUILD_TASK_CONCURRENCY=5

# Build task polling interval in seconds (how often to check for new build_tasks)
ACTION_BUILDER_BUILD_TASK_POLL_INTERVAL_SECONDS=5

# Stale build_task timeout in minutes (for crash recovery of action_build/running tasks)
ACTION_BUILDER_BUILD_TASK_STALE_TIMEOUT_MINUTES=15

# BuildTaskRunner Settings
# ------------------------
# Status check interval in seconds (how often BuildTaskRunner polls recording_tasks status)
ACTION_BUILDER_CHECK_INTERVAL_SECONDS=5

# RecordingTaskQueueWorker Settings
# ----------------------------------
# Maximum number of concurrent recording_tasks (browser instances, global queue shared by all build_tasks)
ACTION_BUILDER_RECORDING_TASK_CONCURRENCY=3

# Stale recording_task timeout in minutes (tasks with no heartbeat are recovered)
ACTION_BUILDER_STALE_TIMEOUT_MINUTES=15

# Task execution timeout in minutes (prevents tasks from hanging indefinitely, saves partial results on timeout)
ACTION_BUILDER_TASK_TIMEOUT_MINUTES=10

# Maximum retry attempts for failed/stale tasks
ACTION_BUILDER_MAX_ATTEMPTS=3

# Recording Task Settings
# ------------------------
# Browser mode (set to 'false' to show browser window for debugging)
ACTION_BUILDER_HEADLESS=true

# Maximum LLM conversation turns per recording task
ACTION_BUILDER_MAX_TURNS=30

# Output directory for generated YAML files
OUTPUT_DIR=./output

# Logging Settings
# ----------------
# Quiet mode: only task-level logs to console, detailed logs to file
# Set to 'false' to output all logs to console (verbose mode)
ACTION_BUILDER_QUIET=true

# -----------------------------------------------------------------------------
# Common Bedrock Model IDs (for reference)
# -----------------------------------------------------------------------------
# anthropic.claude-3-5-sonnet-20241022-v2:0  - Claude 3.5 Sonnet v2
# anthropic.claude-3-5-haiku-20241022-v1:0   - Claude 3.5 Haiku
# anthropic.claude-3-haiku-20240307-v1:0     - Claude 3 Haiku
# meta.llama3-1-70b-instruct-v1:0            - Llama 3.1 70B
# meta.llama3-1-8b-instruct-v1:0             - Llama 3.1 8B
# mistral.mistral-large-2407-v1:0            - Mistral Large
# us.anthropic.claude-sonnet-4-20250514-v1:0 - Claude Sonnet 4 (cross-region)
